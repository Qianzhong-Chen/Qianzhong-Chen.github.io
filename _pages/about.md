---
permalink: /
title: "Qianzhong Chen's Website"
excerpt: "Qianzhong Chen's Website"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I'm a first year PhD student of [Stanford Aero-Astro Department](https://aa.stanford.edu/), advised by Dr. [Mac Schwager](https://web.stanford.edu/~schwager/). Previous to that, I was a research assistant at [UIUC-ACRL](https://naira.mechse.illinois.edu/), advised by Dr. [Naira Hovakimyan](https://mechse.illinois.edu/people/profile/nhovakim) and Dr. [Sheng Cheng](https://sheng-cheng.github.io/). 

I also spent time at [xdof.ai](https://www.xdof.ai/), [Unitree](https://www.unitree.com/), [Centrillion](https://www.centrilliontech.com/) working as robotics engineering/research intern. I was fortunate to be advised by [Philipp Wu](https://wuphilipp.github.io/) (xdof.ai), [Fred Shentu](https://fredshentu.github.io/) (xdof.ai).

My interests and background are across robot VLA model, world model, progress-based reward model, and autonomous drones visual navigation. 

I received my Bachelor's degree in Mechanical Engineering from both Zhejiang University and UIUC in 2023. I received my Master's degree in Mechanical Engineering from Stanford University in 2025.

My Resume can be found [here](https://drive.google.com/file/d/1EaNpeg3MZBYarqiUz-3ov_aR61ki7okc/view?usp=sharing) (updated Dec. 2025).

Feel free to contact me via email (qchen23 {at} stanford.edu), [linkedin](https://www.linkedin.com/in/qianzhong-chen-9bab01209/) or WeChat: CQZ_David.

**[OPEN TO WORK]**: I am actively seeking research internship opportunities for Summer 2026. My research interests include Vision-Language-Action (VLA) models and World Models, with applications in both robot manipulation and autonomous driving.

Selected Publications ([Full list](https://qianzhong-chen.github.io/publications/))
------
<div class="publication" style="display: flex; align-items: stretch; margin-bottom: 30px;">
  <img src="/images/publications/sarm.png" alt="sarm" style="width: 240px; height: 150px; object-fit: fill; margin-right: 20px; border-radius: 8px;">
  <div>
    <strong> SARM: Stage-Aware Reward Modeling for Long Horizon Robot Manipulation</strong><br>
    <strong>Q. Chen</strong>, J. Yu, M. Schwager, P. Abbeel, F. Shentu, P. Wu<br>
    <a href="https://arxiv.org/abs/2509.25358" target="_blank">arXiv</a> |
    <a href="https://qianzhong-chen.github.io/sarm.github.io/" target="_blank">website</a> |
    <a href="https://qianzhong-chen.github.io/sarm.github.io/" target="_blank">code</a><br><br>
    <strong>TL;DR:</strong> SARM is a stage-aware, video-based reward modeling framework that enables scalable and robust imitation learning for long-horizon tasks by deriving progress signals from natural language annotations, dramatically improving policy performance over standard behavior cloning.
  </div>
</div>

<div class="publication" style="display: flex; align-items: stretch; margin-bottom: 30px;">
  <img src="/images/publications/particle_former_website.jpg" alt="ParticleFormer" style="width: 240px; height: 150px; object-fit: fill; margin-right: 20px; border-radius: 8px;">
  <div>
    <strong>[CoRL 2025] ParticleFormer: A 3D Point Cloud World Model for Multi-Object, Multi-Material Robotic Manipulation</strong><br>
    S. Huang, <strong>Q. Chen</strong>, X. Zhang, J. Sun, M. Schwager<br>
    <a href="https://arxiv.org/abs/2506.23126" target="_blank">arXiv</a> |
    <a href="https://suninghuang19.github.io/particleformer_page/" target="_blank">website</a> |
    <a href="https://suninghuang19.github.io/particleformer_page/" target="_blank">code</a><br><br>
    <strong>TL;DR:</strong> A state-of-the-art 3D world model trained directly from point clouds, which enables accurate dynamics prediction across multi-object, multi-material scenarios and empowers model-based visuomotor control in robotic manipulation tasks.
  </div>
</div>

<div class="publication" style="display: flex; align-items: stretch; margin-bottom: 30px;">
  <img src="/images/publications/grad_nav_pp.png" alt="DroneVLA" style="width: 240px; height: 150px; object-fit: fill; margin-right: 20px; border-radius: 8px;">
  <div>
    <strong> [RA-L 2025] GRaD-Nav++: Vision-Language Model Enabled Visual Drone Navigation with Gaussian Radiance Fields and Differentiable Dynamics</strong><br>
    <strong>Q. Chen</strong>, N. Gao, S. Huang, J. Low, T. Chen, J. Sun, M. Schwager<br>
    <a href="https://www.arxiv.org/abs/2506.14009" target="_blank">arXiv</a> |
    <a href="https://qianzhong-chen.github.io/gradnavpp.github.io/" target="_blank">website</a> |
    <a href="https://github.com/Qianzhong-Chen/grad_nav" target="_blank">code</a><br><br>
    <strong>TL;DR:</strong> GRaD-Nav++ is a lightweight, fully onboard Vision-Language-Action framework that enables drones to follow natural language commands in real time using DiffRL training in a 3DGS simulator, achieving strong generalization across tasks and environments both in simulation and on real hardware.
  </div>
</div>

Recent news
------
* 2025/11: Our new paper [GRaD-Nav++](https://qianzhong-chen.github.io/gradnavpp.github.io/) on drone VLA has been accepted to RA-L 2025!
* 2025/08: Our new paper [ARCH](https://long-horizon-assembly.github.io/) on RL for manipulations has been accepted to CoRL 2025!
* 2025/08: Our new paper [ParticleFormer](https://suninghuang19.github.io/particleformer_page/) on 3D world model for manipulations has been accepted to CoRL 2025!
* 2025/06: Our new paper [GRaD-Nav](https://qianzhong-chen.github.io/gradnav.github.io/) on drone end-to-end visual navigation has been accepted to IROS 2025!
* 2025/06: Our new paper [DiffTune-HECTOR](https://sites.google.com/view/difftune-hector/home) on auto-tuning bipedal robots MPC controllers has been accepted to IROS 2025!
* 2025/04: I was admitted to the [Aeronautics and Astronautics Department, Stanford University](https://aa.stanford.edu) as a PhD student, supervised by [Dr. Mac Schwager](https://web.stanford.edu/~schwager/).
<!-- * 2024/06: I started a new role as robotics algorithm engineer at [Centrillion Technologies](https://www.centrilliontech.com/), focusing on building LLM-driven mobile manipulation robot for bio-science lab experiments assistance.   -->
  
<!-- * 2024/02: I started a new role as research assistant at [Stanford-MSL](https://msl.stanford.edu/), my project is end-to-end mobile robot navigation and control policy based on 3DGS and differentiable RL. -->

<!-- * 2023/10: I present my RA-L paper on [IROS 2023](https://ieee-iros.org/), my poster can be found [here](https://drive.google.com/file/d/1kgR-Wkw_1a_R67KK-74c22X9KeGUi6sc/view?usp=drive_link), with some event photos [photo1](https://drive.google.com/file/d/1ewSDxctsEqfInZprZgRUn82ginDMWBJq/view?usp=drive_link) [photo2](https://drive.google.com/file/d/1Xq9Uasjo0LTI3LR7Ays0lBjOwlJr5lix/view?usp=drive_link)
* 2023/09: I started my Master of Science in Mechanical Engineering at Stanford University
* 2023/06: I joined [Unitree Robotics](https://m.unitree.com/) as an intern robotics control enginer, focusing on quadrupedal robot deep reinforcement learning control and locomotion.
* 2023/06: I graduated from Zhejiang University, with a Bachelor of Enginineering in Mechanical Engineering.
* 2023/06: I graduated from University of Illinois Urbana-Champaign, with a Bachelor of Science in Mechanical Engineering.
* 2023/04: Our new paper on fast UAV trajectory planning via simultaneous spatial and temporal assignments has been accepted by IEEE RA-L! The preprint is available on [arxiv](https://arxiv.org/abs/2211.15902). -->

Honors and awards
------

* Stanford Aero-Astro PhD Fellowship (2025)
* Outstanding Undergraduate Thesis Award, Department of Mechanical Engineering, Zhejiang University (2023) 
* First Class Academic Scholarship of ZJU-UIUC Institute (**Top 1%**) (2022)

<!-- * Dean's List of UIUC (2022) -->

Service
------
<!-- * Journal Reviewer: IEEE Transactions on Control Systems Technology, Automatica, Journal of Guidance, Control, and Dynamics, IEEE Control Systems Letters, IEEE Transactions on Aerospace and Electronic Systems, IEEE Transactions on Industrial Informatics -->
* Journal Articles Reviewer: IEEE RA-L (2025), IEEE IoT (2025)  
* Conference Reviewer: IROS (2025), ICRA (2026) 
* Member of the IEEE Robotics and Automation Society
